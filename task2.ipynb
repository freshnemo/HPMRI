{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01364009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from libauc.losses import AUCMLoss \n",
    "from libauc.optimizers import PESG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d910fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_optimizer import PCGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ebab875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17708/2080976236.py:6: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader,WeightedRandomSampler\n",
    "from torch.nn import MultiheadAttention,Linear, ReLU, RNN,Sigmoid,Softmax\n",
    "import torch \n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from sklearn.metrics import mean_absolute_error,r2_score,roc_auc_score,f1_score,balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split,RepeatedKFold\n",
    "#sklearn.model_selection.RepeatedKFold\n",
    "#from pcgrad import PCGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f8f3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import NMR_matrix, NMR_mask_matrix, return_NMR_pad, return_pad, check_max_len_img, FindCorner, FindNonzero2D\n",
    "from modules import return_img_pad, check_max_len, check_max_len_img_hp, return_ph_pad, LoadData, mult_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4662c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCBTP_data(Dataset):\n",
    "\n",
    "    def __init__(self, mouse_index, HPMRI, NMR, NMR_mask,sag_path,cor_path,ax_path,hp_path ):\n",
    "        \n",
    "        self.mouse_index = mouse_index\n",
    "        self.HPMRI=HPMRI\n",
    "        self.NMR=NMR\n",
    "        self.NMR_mask=NMR_mask\n",
    "        self.sag_path=sag_path\n",
    "\n",
    "        self.cor_path=cor_path\n",
    "        self.ax_path=ax_path\n",
    "        self.sag_max, self.sag_loc =check_max_len_img(sag_path)\n",
    "        self.cor_max, self.cor_loc=check_max_len_img(cor_path)\n",
    "        self.ax_max, self.ax_loc=check_max_len_img(ax_path)\n",
    "        self.max_seq=check_max_len(HPMRI)\n",
    "        \n",
    "        \n",
    "        self.hp_path=hp_path\n",
    "        self.hp_max_r, self.hp_max_c= check_max_len_img_hp(hp_path) #['agg_index']\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mouse_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get locations of a fixed 2d area working for ax, sag and cor \n",
    "        loc_all = []\n",
    "        for i in range(4):\n",
    "            if i%2==0:\n",
    "                loc_all.append(min(self.sag_loc[i],self.cor_loc[i],self.ax_loc[i]))\n",
    "            else:\n",
    "                loc_all.append(max(self.sag_loc[i],self.cor_loc[i],self.ax_loc[i]))\n",
    "        mouse=self.mouse_index.iloc[idx].Mouse_Name\n",
    "\n",
    "        coh=self.mouse_index.iloc[idx].Cohort\n",
    "\n",
    "        mouse_class = self.mouse_index.iloc[idx].Label\n",
    "\n",
    "        pt_HPMRI=self.HPMRI[self.HPMRI.Mouse_Name==mouse]\n",
    "\n",
    "        pt_HPMRI=pt_HPMRI.sort_values(by='Days_Elapsed').drop(columns=['Mouse_Name','Cohort','Days_Elapsed']).values\n",
    "        pt_HPMRI=return_pad(pt_HPMRI,self.max_seq)\n",
    "        pt_NMR=self.NMR[self.NMR.Mouse_Name==mouse]\n",
    "        #pt_NMR=pt_NMR.sort_values(by='Days_Elapsed').drop(columns=['Mouse_Name','Cohort','Days_Elapsed','tumor_index']).values\n",
    "        pt_NMR=pt_NMR.sort_values(by='Days_Elapsed').drop(columns=['Mouse_Name','Cohort','Days_Elapsed']).values\n",
    "        \n",
    "        pt_NMR=return_pad(pt_NMR,self.max_seq)\n",
    "\n",
    "        pt_NMR_mask=self.NMR_mask[self.NMR_mask.Mouse_Name==mouse]\n",
    "        pt_NMR_mask=pt_NMR_mask.sort_values(by='Days_Elapsed').drop(columns=['Mouse_Name','Cohort','Days_Elapsed']).values\n",
    "        pt_NMR_mask=return_pad(pt_NMR_mask,self.max_seq)\n",
    "    \n",
    "        pt_sag=self.sag_path[self.sag_path.Mouse_Name==mouse]\n",
    "        pt_sag=return_img_pad (pt_sag,self.max_seq,self.sag_max,loc_all)\n",
    "        pt_cor=self.cor_path[self.cor_path.Mouse_Name==mouse]\n",
    "        pt_cor=return_img_pad (pt_cor,self.max_seq,self.cor_max,loc_all)\n",
    "        pt_ax=self.ax_path[self.ax_path.Mouse_Name==mouse]\n",
    "        pt_ax=return_img_pad(pt_ax,self.max_seq,self.ax_max,loc_all)  \n",
    "\n",
    "\n",
    "\n",
    "        # ht_hp, raw data\n",
    "        #print('pt_hp', self.hp_path.shape)      \n",
    "        pt_hp=self.hp_path[self.hp_path.Mouse_Name==mouse]\n",
    "        pt_hp=return_ph_pad(pt_hp, self.max_seq, self.hp_max_r, self.hp_max_c)\n",
    " \n",
    "       \n",
    "        return (pt_HPMRI,pt_NMR,pt_NMR_mask,pt_sag,pt_cor,pt_ax, mouse_class, pt_hp, mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2790726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCBTP_attn(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CCBTP_attn, self).__init__()\n",
    "        self.emb_size=config['emb_size']\n",
    "        \n",
    "        self.Lin_img_1=nn.Linear(config['img_pix_nu'],config['emb_size'],bias=False)\n",
    "        self.Lin_img_2=nn.Linear(config['img_pix_nu'],config['emb_size'],bias=False)\n",
    "        self.Lin_img_3=nn.Linear(config['img_pix_nu'],config['emb_size'],bias=False)\n",
    "        \n",
    "        self.Lin_img_all=nn.Linear(config['emb_size']*9,config['emb_size']*3)\n",
    "        self.MuA_1=mult_attn(config).cuda()\n",
    "        self.MuA_2=mult_attn(config).cuda()\n",
    "        self.MuA_3=mult_attn(config).cuda()\n",
    "        self.relu=ReLU()\n",
    "        self.sigmoid=Sigmoid()\n",
    "        self.Softmax=Softmax()\n",
    "\n",
    "\n",
    "\n",
    "        self.conv1_3d = self._conv_layer_set_3d(1, 64)\n",
    "        self.conv2_3d = self._conv_layer_set_3d(64, 128, h_size = 1)\n",
    "        self.conv3_3d = self._conv_layer_set_3d(128, self.emb_size, h_size = 1)\n",
    "\n",
    "        self.conv_hp1 = self._conv_layer_set_2d(1, 8)\n",
    "        self.conv_hp2 = self._conv_layer_set_2d(8, 16)\n",
    "        \n",
    "        self.rnn_t=RNN(input_size=8,hidden_size=3,num_layers=config['rnn_layers'],\n",
    "                    batch_first=True,dropout=config['drop_rate']\n",
    "                    )\n",
    "        self.rnn_hp=RNN(input_size=9,hidden_size=9,num_layers=config['rnn_layers'],\n",
    "                    batch_first=True,dropout=config['drop_rate']\n",
    "                    )\n",
    "        \n",
    "        self.rnn_hp_raw=RNN(input_size=280,hidden_size=config['rnn_hidden_size'],num_layers=config['rnn_layers'],\n",
    "                    batch_first=True,dropout=config['drop_rate']\n",
    "                    )\n",
    "        \n",
    "        self.final_lin2=nn.Linear(908,2,bias=True) \n",
    "        \n",
    "        \n",
    "    def forward(self,pt_HPMRI,pt_sag,pt_cor,pt_ax,pt_hp, NMR_data): \n",
    "\n",
    "        pt_sag=pt_sag.permute(1, 0,2,3,4)        \n",
    "        pt_cor=pt_cor.permute(1, 0,2,3, 4)\n",
    "        pt_ax=pt_ax.permute(1, 0,2,3,4)\n",
    "        pt_hp=pt_hp.permute(1, 0,2,3)\n",
    "        convs_size_sag, convs_size_cor, convs_size_ax= pt_sag.size(2), pt_cor.size(2), pt_ax.size(2)\n",
    "        timestep=pt_ax.size()[0]\n",
    "        batch=pt_ax.size()[1]\n",
    "        input_rnn=torch.empty(size=(timestep*3, batch ,self.emb_size))\n",
    "        input_rnn_hp=torch.empty(size=(timestep, batch ,280))\n",
    "        for i in range(timestep):\n",
    "\n",
    "            # 3d for images\n",
    "            pt_sag_temp=pt_sag[i].float()\n",
    "            pt_sag_temp = self.convs_3d(pt_sag_temp)\n",
    "\n",
    "            pt_cor_temp=pt_cor[i].float()\n",
    "            pt_cor_temp = self.convs_3d(pt_cor_temp)\n",
    "            \n",
    "            pt_ax_temp=pt_ax[i].float()\n",
    "            pt_ax_temp = self.convs_3d(pt_ax_temp)\n",
    "\n",
    "\n",
    "            pt_hp_temp=pt_hp[i].float().unsqueeze(1)\n",
    "            pt_hp_temp = self.conv_hp1(pt_hp_temp)\n",
    "            pt_hp_temp = self.conv_hp2(pt_hp_temp)\n",
    "            #print(pt_hp_temp.size())\n",
    "            pt_hp_temp = torch.max(pt_hp_temp, 1)[0].reshape(batch, -1)\n",
    "\n",
    "            input_rnn[i], input_rnn[i+timestep], input_rnn[i+timestep*2]= pt_sag_temp, pt_cor_temp, pt_ax_temp\n",
    "            input_rnn_hp[i] = pt_hp_temp\n",
    "\n",
    "        pt_sag_temp = input_rnn[:timestep,:,:].cuda()\n",
    "        pt_cor_temp = input_rnn[timestep:timestep*2,:,:].cuda()\n",
    "        pt_ax_temp = input_rnn[timestep*2:,:,:].cuda()\n",
    "        \n",
    "        pt_ax_attn=self.MuA_1(pt_ax_temp,pt_cor_temp,pt_sag_temp)\n",
    "        pt_cor_attn=self.MuA_2(pt_cor_temp,pt_ax_temp,pt_sag_temp)\n",
    "        pt_sag_attn=self.MuA_3(pt_sag_temp,pt_cor_temp,pt_ax_temp)\n",
    "        pt_att_final=self.Lin_img_all(torch.cat((pt_ax_attn, pt_cor_attn,pt_sag_attn),dim=1))\n",
    "        \n",
    "        pt_att_final=self.relu(pt_att_final)\n",
    "\n",
    "        # To here, images along days from (batch, days, embd) to (batch, embd)\n",
    "        # HPMRI w/wo raw, tumor still (batch, days, emb)\n",
    "        \n",
    "        #all_time_attn=all_time_attn.permute(1, 0,2).cuda()\n",
    "\n",
    "        pt_HPMRI,_ = self.rnn_hp(pt_HPMRI)\n",
    "        rnn_output_hp,_ = self.rnn_hp_raw(input_rnn_hp.permute(1, 0,2).cuda())\n",
    "        pt_tumor, _ = self.rnn_t(NMR_data)\n",
    "\n",
    "\n",
    "        pt_HPMRI, rnn_output_hp, pt_tumor = pt_HPMRI[:,-1,:], rnn_output_hp[:,-1,:], pt_tumor[:,-1,:]\n",
    "        \n",
    "        all_rnn_input=torch.cat((pt_att_final,rnn_output_hp,pt_HPMRI,pt_tumor),dim=1)\n",
    "        \n",
    "        \n",
    "        pred=self.final_lin2(all_rnn_input)\n",
    "        #pred =self.Softmax(pred)\n",
    "        #pred = self.sigmoid(pred)\n",
    "        \n",
    "        return pred \n",
    "\n",
    "    def _conv_layer_set_2d(self, in_c, out_c):\n",
    "        conv_layer = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=( 3, 3), padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((3, 3)),\n",
    "        )\n",
    "        return conv_layer\n",
    "\n",
    "    def _conv_layer_set_3d(self, in_c, out_c, h_size=2):\n",
    "        conv_layer = nn.Sequential(\n",
    "        nn.Conv3d(in_c, out_c, kernel_size=( h_size, 3, 3), padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool3d((h_size, 3, 3)),\n",
    "        )\n",
    "        return conv_layer\n",
    "\n",
    "    def convs_3d(self,pt_sag_temp):\n",
    "        \n",
    "        pt_sag_temp = pt_sag_temp.unsqueeze(1)\n",
    "        pt_sag_temp=self.conv1_3d(pt_sag_temp)\n",
    "        pt_sag_temp=self.conv2_3d(pt_sag_temp)\n",
    "        pt_sag_temp=self.conv3_3d(pt_sag_temp)\n",
    "        pt_sag_temp=pt_sag_temp.reshape(pt_sag_temp.size(0), self.emb_size, -1).max(-1)[0]\n",
    "        \n",
    "        return pt_sag_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdcb5ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unit(model,dataloader,class_weights):\n",
    "    optimizer=Adam(model.parameters(),lr=0.001)\n",
    "    all_loss=[]\n",
    "    model.train()\n",
    "    #lr = 0.1\n",
    "    #margin = 1.0\n",
    "    #epoch_decay = 0.003 # refers gamma in the paper\n",
    "    #weight_decay = 0.0001\n",
    "    #loss_fn = AUCMLoss()\n",
    "    #optimizer = PESG(model.parameters(),\n",
    "                 #loss_fn=loss_fn,\n",
    "                 #lr=0.05,\n",
    "                 #momentum=0.9,\n",
    "                 #margin=margin,\n",
    "                 #epoch_decay=epoch_decay,\n",
    "                 #weight_decay=weight_decay) \n",
    "    #criterion=nn.BCELoss()\n",
    "    criterion= nn.CrossEntropyLoss(weight=class_weights.cuda())\n",
    "    mouse_n, inf = [], []\n",
    "    for iteration, data_u in enumerate(dataloader):\n",
    "        HPNRI_data=data_u[0].float() \n",
    "        NMR_data=data_u[1].float() \n",
    "        NMR_data_mask_1=data_u[2].float() \n",
    "        sag_data=data_u[3].float()\n",
    "        cor_data=data_u[4].float()\n",
    "        ax_data=data_u[5].float()\n",
    "        classinf=Variable(data_u[6]).float()\n",
    "        pt_hp = Variable(data_u[7]).float()\n",
    "\n",
    "        \n",
    "        HPNRI_data=HPNRI_data.cuda()\n",
    "        NMR_data=NMR_data.cuda()\n",
    "        sag_data=sag_data.cuda()\n",
    "        cor_data=cor_data.cuda()\n",
    "        ax_data=ax_data.cuda()\n",
    "        classinf= classinf.cuda()\n",
    "        pt_hp = pt_hp.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        rnn_output=model(HPNRI_data,sag_data,cor_data,ax_data, pt_hp, NMR_data)\n",
    "        #rnn_output = torch.softmax(rnn_output)\n",
    "        #print(rnn_output)\n",
    "        loss = criterion(rnn_output, classinf.long())\n",
    "        #loss=criterion(rnn_output.reshape(-1),classinf)\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_loss.append(loss.cpu().data.numpy().item())\n",
    "    \n",
    "    return all_loss,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd817b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_unit(model,dataloader, sv=False):\n",
    "    all_result_1=[]\n",
    "    all_gold_1=[]\n",
    "\n",
    "    all_loss=[]\n",
    "    model.eval() \n",
    "\n",
    "    with torch.no_grad():\n",
    "        mouse_n, inf = [], []\n",
    "        for iteration, data_u in enumerate(dataloader):\n",
    "            HPNRI_data=data_u[0].float() \n",
    "            NMR_data=data_u[1].float() \n",
    "            NMR_data_mask_1=data_u[2].float() \n",
    "            sag_data=data_u[3].float()\n",
    "            cor_data=data_u[4].float()\n",
    "            ax_data=data_u[5].float()\n",
    "\n",
    "            classinf=Variable(data_u[6]).float()\n",
    "            pt_hp = Variable(data_u[7]).float()\n",
    "\n",
    "            # mouse_n: name, label, prediction(0/1),prediction_prob\n",
    "            \n",
    "            mouse_n = np.concatenate((mouse_n,data_u[8].numpy()))\n",
    "            mouse_n = np.concatenate((mouse_n,data_u[6].numpy().reshape(-1)))\n",
    "            \n",
    "            \n",
    "            HPNRI_data=HPNRI_data.cuda()\n",
    "            NMR_data=NMR_data.cuda()\n",
    "            sag_data=sag_data.cuda()\n",
    "            cor_data=cor_data.cuda()\n",
    "            ax_data=ax_data.cuda()\n",
    "            classinf= classinf.cuda()\n",
    "            pt_hp = pt_hp.cuda()\n",
    "\n",
    "            rnn_output=model(HPNRI_data,sag_data,cor_data,ax_data, pt_hp, NMR_data)\n",
    "            #rnn_output = torch.sigmoid(rnn_output)\n",
    "            #print(rnn_output)\n",
    "            #print( )\n",
    "            pred_ = rnn_output.cpu().detach().numpy().argmax(axis=1)\n",
    "            #print(pred_)\n",
    "            #pred_[pred_ < 0.5] = 0\n",
    "            #pred_[pred_ >= 0.5] = 1\n",
    "            mouse_n = np.concatenate((mouse_n,pred_.reshape(-1)))\n",
    " \n",
    "            all_result_1.append(pred_)#rnn_output.cpu().detach().numpy())\n",
    "            all_gold_1.append(classinf.cpu().detach().numpy())\n",
    "            \n",
    "\n",
    "        if sv:\n",
    "            with open('task2_predictions.csv', 'wb') as f:\n",
    "                np.savetxt(f, np.array(np.asarray(mouse_n).reshape(-1,3)), delimiter=',', fmt='%d') \n",
    "            \n",
    "    return all_result_1,all_gold_1,mouse_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2091d4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day on 41\n"
     ]
    }
   ],
   "source": [
    "val = False # if validation only\n",
    "    \n",
    "device=1\n",
    "torch.cuda.set_device(device)\n",
    "dayy = '41'\n",
    "print('Day on', dayy)\n",
    "\n",
    "rr = 'raw/task2/'\n",
    "\n",
    "        \n",
    "data_path='./NMR_Prediction/NMR_Before_Day_'+dayy+'/'\n",
    "\n",
    "\n",
    "savemodelpath='./model_result/'+rr+'att_1_day_'+dayy+'_class.pth'\n",
    "if not os.path.exists('./model_result/raw/task2/'+dayy):\n",
    "    os.makedirs('./model_result/raw/task2/'+dayy)\n",
    "\n",
    "filelist=os.listdir(data_path)\n",
    "filelist=[i for i in filelist if i.startswith('all')]\n",
    "filelist.sort()\n",
    "\n",
    "\n",
    "    # Load data from Treated cohort\n",
    "HPMRI, HPMRI_mask, NMR, NMR_true, NMR_mask, tumor, tumor_mask, sag_path, cor_path, ax_path, hp_path= LoadData(data_path, cohort = 'Treated')\n",
    "\n",
    "    # Load label\n",
    "task2_label = pd.read_csv('./treated_mice_day41_effect.csv')\n",
    "task2_label.columns=['Mouse_Name','Cohort','Label']\n",
    "task2_label['Label']=np.where(task2_label['Label']=='Yes',1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8c006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82398ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "config={'img_pix_nu':49152,\n",
    "            'emb_size': 256,\n",
    "            'head_nu':1,# 2\n",
    "            'drop_rate' :0.2,\n",
    "            'rnn_int_size': 256*3+9+3,\n",
    "            'rnn_hidden_size': 128, # was 256\n",
    "            'rnn_layers': 1}# was 2\n",
    "\n",
    "model=CCBTP_attn(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c62478c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45f852b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPMRI, HPMRI_mask, NMR, NMR_true, NMR_mask, tumor, tumor_mask, sag_path, cor_path, ax_path, hp_path= LoadData(data_path, cohort = 'Treated')\n",
    "\n",
    "    # Load label\n",
    "task2_label = pd.read_csv('./treated_mice_day41_effect.csv')\n",
    "task2_label.columns=['Mouse_Name','Cohort','Label']\n",
    "task2_label['Label']=np.where(task2_label['Label']=='Yes',1,0)\n",
    "train_index=task2_label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a138740",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1= CCBTP_data(train_index, HPMRI, NMR, NMR_mask,sag_path,cor_path,ax_path,hp_path )\n",
    "train_loader_1 = DataLoader(train_1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57eae3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_u=next(iter(train_loader_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3aaa698",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPNRI_data=data_u[0].float() \n",
    "NMR_data=data_u[1].float() \n",
    "NMR_data_mask_1=data_u[2].float() \n",
    "sag_data=data_u[3].float()\n",
    "cor_data=data_u[4].float()\n",
    "ax_data=data_u[5].float()\n",
    "\n",
    "classinf=Variable(data_u[6]).float()\n",
    "pt_hp = Variable(data_u[7]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d68cad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[19.1017, 19.2533, 16.3904,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [15.0922, 19.0773, 19.2900,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [13.2585, 17.5052, 17.1752,  ..., 17.3830, 17.3414, 15.5078],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b73c7ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.9434e-01, 4.1817e-01, 7.0000e+00, 5.9576e+03, 5.2000e+01,\n",
       "          1.0000e+00, 1.8000e+01, 1.6017e+03, 9.9000e+01],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HPNRI_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c409500d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7, 107, 147])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(sag_data).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3af989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary=summary(model,batch_dim=1,input_size=(torch.squeeze(HPNRI_data).size(),torch.squeeze(sag_data).size(),torch.squeeze(cor_data).size(),torch.squeeze(ax_data).size(), torch.squeeze(pt_hp).size(), torch.squeeze(NMR_data).size()),row_settings=[\"var_names\"],col_names=[\"kernel_size\", \"output_size\", \"num_params\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e114bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type (var_name))                  Kernel Shape              Output Shape              Param #\n",
       "===================================================================================================================\n",
       "CCBTP_attn (CCBTP_attn)                  --                        [4, 2]                    37,748,736\n",
       "├─Sequential (conv1_3d)                  --                        [4, 64, 3, 35, 48]        --\n",
       "│    └─Conv3d (0)                        [2, 3, 3]                 [4, 64, 6, 105, 145]      1,216\n",
       "│    └─ReLU (1)                          --                        [4, 64, 6, 105, 145]      --\n",
       "│    └─MaxPool3d (2)                     [2, 3, 3]                 [4, 64, 3, 35, 48]        --\n",
       "├─Sequential (conv2_3d)                  --                        [4, 128, 3, 11, 15]       --\n",
       "│    └─Conv3d (0)                        [1, 3, 3]                 [4, 128, 3, 33, 46]       73,856\n",
       "│    └─ReLU (1)                          --                        [4, 128, 3, 33, 46]       --\n",
       "│    └─MaxPool3d (2)                     [1, 3, 3]                 [4, 128, 3, 11, 15]       --\n",
       "├─Sequential (conv3_3d)                  --                        [4, 256, 3, 3, 4]         --\n",
       "│    └─Conv3d (0)                        [1, 3, 3]                 [4, 256, 3, 9, 13]        295,168\n",
       "│    └─ReLU (1)                          --                        [4, 256, 3, 9, 13]        --\n",
       "│    └─MaxPool3d (2)                     [1, 3, 3]                 [4, 256, 3, 3, 4]         --\n",
       "├─Sequential (conv1_3d)                  --                        [4, 64, 2, 35, 48]        (recursive)\n",
       "│    └─Conv3d (0)                        [2, 3, 3]                 [4, 64, 5, 105, 145]      (recursive)\n",
       "│    └─ReLU (1)                          --                        [4, 64, 5, 105, 145]      --\n",
       "│    └─MaxPool3d (2)                     [2, 3, 3]                 [4, 64, 2, 35, 48]        --\n",
       "├─Sequential (conv2_3d)                  --                        [4, 128, 2, 11, 15]       (recursive)\n",
       "│    └─Conv3d (0)                        [1, 3, 3]                 [4, 128, 2, 33, 46]       (recursive)\n",
       "│    └─ReLU (1)                          --                        [4, 128, 2, 33, 46]       --\n",
       "│    └─MaxPool3d (2)                     [1, 3, 3]                 [4, 128, 2, 11, 15]       --\n",
       "├─Sequential (conv3_3d)                  --                        [4, 256, 2, 3, 4]         (recursive)\n",
       "│    └─Conv3d (0)                        [1, 3, 3]                 [4, 256, 2, 9, 13]        (recursive)\n",
       "│    └─ReLU (1)                          --                        [4, 256, 2, 9, 13]        --\n",
       "│    └─MaxPool3d (2)                     [1, 3, 3]                 [4, 256, 2, 3, 4]         --\n",
       "├─Sequential (conv1_3d)                  --                        [4, 64, 4, 35, 48]        (recursive)\n",
       "│    └─Conv3d (0)                        [2, 3, 3]                 [4, 64, 8, 105, 145]      (recursive)\n",
       "│    └─ReLU (1)                          --                        [4, 64, 8, 105, 145]      --\n",
       "│    └─MaxPool3d (2)                     [2, 3, 3]                 [4, 64, 4, 35, 48]        --\n",
       "├─Sequential (conv2_3d)                  --                        [4, 128, 4, 11, 15]       (recursive)\n",
       "│    └─Conv3d (0)                        [1, 3, 3]                 [4, 128, 4, 33, 46]       (recursive)\n",
       "│    └─ReLU (1)                          --                        [4, 128, 4, 33, 46]       --\n",
       "│    └─MaxPool3d (2)                     [1, 3, 3]                 [4, 128, 4, 11, 15]       --\n",
       "├─Sequential (conv3_3d)                  --                        [4, 256, 4, 3, 4]         (recursive)\n",
       "│    └─Conv3d (0)                        [1, 3, 3]                 [4, 256, 4, 9, 13]        (recursive)\n",
       "│    └─ReLU (1)                          --                        [4, 256, 4, 9, 13]        --\n",
       "│    └─MaxPool3d (2)                     [1, 3, 3]                 [4, 256, 4, 3, 4]         --\n",
       "├─Sequential (conv_hp1)                  --                        [4, 8, 5, 843]            --\n",
       "│    └─Conv2d (0)                        [3, 3]                    [4, 8, 16, 2530]          80\n",
       "│    └─ReLU (1)                          --                        [4, 8, 16, 2530]          --\n",
       "│    └─MaxPool2d (2)                     [3, 3]                    [4, 8, 5, 843]            --\n",
       "├─Sequential (conv_hp2)                  --                        [4, 16, 1, 280]           --\n",
       "│    └─Conv2d (0)                        [3, 3]                    [4, 16, 3, 841]           1,168\n",
       "│    └─ReLU (1)                          --                        [4, 16, 3, 841]           --\n",
       "│    └─MaxPool2d (2)                     [3, 3]                    [4, 16, 1, 280]           --\n",
       "├─mult_attn (MuA_1)                      --                        [4, 768]                  --\n",
       "│    └─MultiheadAttention (MuA_1)        --                        [1, 1, 256]               262,144\n",
       "│    └─ReLU (relu)                       --                        [1, 4, 256]               --\n",
       "│    └─MultiheadAttention (MuA_2)        --                        [1, 1, 256]               262,144\n",
       "│    └─MultiheadAttention (MuA_3)        --                        [1, 1, 256]               262,144\n",
       "│    └─ReLU (relu)                       --                        [4, 768]                  --\n",
       "├─mult_attn (MuA_2)                      --                        [4, 768]                  --\n",
       "│    └─MultiheadAttention (MuA_1)        --                        [1, 1, 256]               262,144\n",
       "│    └─ReLU (relu)                       --                        [1, 4, 256]               --\n",
       "│    └─MultiheadAttention (MuA_2)        --                        [1, 1, 256]               262,144\n",
       "│    └─MultiheadAttention (MuA_3)        --                        [1, 1, 256]               262,144\n",
       "│    └─ReLU (relu)                       --                        [4, 768]                  --\n",
       "├─mult_attn (MuA_3)                      --                        [4, 768]                  --\n",
       "│    └─MultiheadAttention (MuA_1)        --                        [1, 1, 256]               262,144\n",
       "│    └─ReLU (relu)                       --                        [1, 4, 256]               --\n",
       "│    └─MultiheadAttention (MuA_2)        --                        [1, 1, 256]               262,144\n",
       "│    └─MultiheadAttention (MuA_3)        --                        [1, 1, 256]               262,144\n",
       "│    └─ReLU (relu)                       --                        [4, 768]                  --\n",
       "├─Linear (Lin_img_all)                   --                        [4, 768]                  1,770,240\n",
       "├─ReLU (relu)                            --                        [4, 768]                  --\n",
       "├─RNN (rnn_hp)                           --                        [4, 1, 9]                 180\n",
       "├─RNN (rnn_hp_raw)                       --                        [4, 1, 128]               52,480\n",
       "├─RNN (rnn_t)                            --                        [4, 1, 3]                 39\n",
       "├─Linear (final_lin2)                    --                        [4, 2]                    1,818\n",
       "===================================================================================================================\n",
       "Total params: 42,304,277\n",
       "Trainable params: 42,304,277\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.72\n",
       "===================================================================================================================\n",
       "Input size (MB): 6.27\n",
       "Forward/backward pass size (MB): 668.70\n",
       "Params size (MB): 8.78\n",
       "Estimated Total Size (MB): 683.76\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a1436f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CCBTP_attn: 0,\n",
       " Sequential: 1,\n",
       " Conv3d: 2,\n",
       " ReLU: 2,\n",
       " MaxPool3d: 2,\n",
       " Sequential: 1,\n",
       " Conv3d: 2,\n",
       " ReLU: 2,\n",
       " MaxPool3d: 2,\n",
       " Sequential: 1,\n",
       " Conv3d: 2,\n",
       " ReLU: 2,\n",
       " MaxPool3d: 2,\n",
       " Sequential: 1,\n",
       " Conv3d: 2,\n",
       " ReLU: 2,\n",
       " MaxPool3d: 2,\n",
       " Sequential: 1,\n",
       " Conv3d: 2,\n",
       " ReLU: 2,\n",
       " MaxPool3d: 2,\n",
       " Sequential: 1,\n",
       " Conv3d: 2,\n",
       " ReLU: 2,\n",
       " MaxPool3d: 2,\n",
       " Sequential: 1,\n",
       " Conv3d: 2,\n",
       " ReLU: 2,\n",
       " MaxPool3d: 2,\n",
       " Sequential: 1,\n",
       " Conv3d: 2,\n",
       " ReLU: 2,\n",
       " MaxPool3d: 2,\n",
       " Sequential: 1,\n",
       " Conv3d: 2,\n",
       " ReLU: 2,\n",
       " MaxPool3d: 2,\n",
       " Sequential: 1,\n",
       " Conv2d: 2,\n",
       " ReLU: 2,\n",
       " MaxPool2d: 2,\n",
       " Sequential: 1,\n",
       " Conv2d: 2,\n",
       " ReLU: 2,\n",
       " MaxPool2d: 2,\n",
       " mult_attn: 1,\n",
       " MultiheadAttention: 2,\n",
       " ReLU: 2,\n",
       " MultiheadAttention: 2,\n",
       " MultiheadAttention: 2,\n",
       " ReLU: 2,\n",
       " mult_attn: 1,\n",
       " MultiheadAttention: 2,\n",
       " ReLU: 2,\n",
       " MultiheadAttention: 2,\n",
       " MultiheadAttention: 2,\n",
       " ReLU: 2,\n",
       " mult_attn: 1,\n",
       " MultiheadAttention: 2,\n",
       " ReLU: 2,\n",
       " MultiheadAttention: 2,\n",
       " MultiheadAttention: 2,\n",
       " ReLU: 2,\n",
       " Linear: 1,\n",
       " ReLU: 1,\n",
       " RNN: 1,\n",
       " RNN: 1,\n",
       " RNN: 1,\n",
       " Linear: 1]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary.summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50219ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_data = []\n",
    "for layer in model_summary.summary_list:\n",
    "    summary_data.append([layer.kernel_size, layer.output_size, layer.num_params])\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(summary_data, columns=[\"Kernel Size\", \"Output Size\", \"Number of Parameters\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4330e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Modula_name']=model_summary.summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c39036ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Kernel Size', 'Output Size', 'Number of Parameters', 'Modula_name'], dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50f5c25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Modula_name','Kernel Size', 'Output Size', 'Number of Parameters']].to_csv('model_para.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7b81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_summary.txt', 'w') as f:\n",
    "    f.write(str(model_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee7a2a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCBTP_attn(\n",
      "  (Lin_img_1): Linear(in_features=49152, out_features=256, bias=False)\n",
      "  (Lin_img_2): Linear(in_features=49152, out_features=256, bias=False)\n",
      "  (Lin_img_3): Linear(in_features=49152, out_features=256, bias=False)\n",
      "  (Lin_img_all): Linear(in_features=2304, out_features=768, bias=True)\n",
      "  (MuA_1): mult_attn(\n",
      "    (MuA_1): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)\n",
      "    )\n",
      "    (MuA_2): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)\n",
      "    )\n",
      "    (MuA_3): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (MuA_2): mult_attn(\n",
      "    (MuA_1): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)\n",
      "    )\n",
      "    (MuA_2): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)\n",
      "    )\n",
      "    (MuA_3): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (MuA_3): mult_attn(\n",
      "    (MuA_1): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)\n",
      "    )\n",
      "    (MuA_2): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)\n",
      "    )\n",
      "    (MuA_3): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=False)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      "  (Softmax): Softmax(dim=None)\n",
      "  (conv1_3d): Sequential(\n",
      "    (0): Conv3d(1, 64, kernel_size=(2, 3, 3), stride=(1, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool3d(kernel_size=(2, 3, 3), stride=(2, 3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2_3d): Sequential(\n",
      "    (0): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3_3d): Sequential(\n",
      "    (0): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_hp1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_hp2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (rnn_t): RNN(8, 3, batch_first=True, dropout=0.2)\n",
      "  (rnn_hp): RNN(9, 9, batch_first=True, dropout=0.2)\n",
      "  (rnn_hp_raw): RNN(280, 128, batch_first=True, dropout=0.2)\n",
      "  (final_lin2): Linear(in_features=908, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61501101",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = False # if validation only\n",
    "    \n",
    "device=1\n",
    "torch.cuda.set_device(device)\n",
    "dayy = '41'\n",
    "print('Day on', dayy)\n",
    "\n",
    "rr = 'raw/task2/'\n",
    "\n",
    "        \n",
    "data_path='./NMR_Prediction/NMR_Before_Day_'+dayy+'/'\n",
    "\n",
    "\n",
    "savemodelpath='./model_result/'+rr+'att_1_day_'+dayy+'_class.pth'\n",
    "if not os.path.exists('./model_result/raw/task2/'+dayy):\n",
    "    os.makedirs('./model_result/raw/task2/'+dayy)\n",
    "\n",
    "filelist=os.listdir(data_path)\n",
    "filelist=[i for i in filelist if i.startswith('all')]\n",
    "filelist.sort()\n",
    "\n",
    "\n",
    "    # Load data from Treated cohort\n",
    "HPMRI, HPMRI_mask, NMR, NMR_true, NMR_mask, tumor, tumor_mask, sag_path, cor_path, ax_path, hp_path= LoadData(data_path, cohort = 'Treated')\n",
    "\n",
    "    # Load label\n",
    "task2_label = pd.read_csv('./treated_mice_day41_effect.csv')\n",
    "task2_label.columns=['Mouse_Name','Cohort','Label']\n",
    "task2_label['Label']=np.where(task2_label['Label']=='Yes',1,0)\n",
    "\n",
    "\n",
    "rkf=RepeatedKFold(n_repeats=5, n_splits=3, random_state=2652124)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(rkf.split(task2_label)):\n",
    "    train_index=task2_label.iloc[train_index]\n",
    "    test_index=task2_label.iloc[test_index]\n",
    "    \n",
    "\n",
    "    #train_index,test_index=train_test_split(task2_label,train_size=0.8,stratify=task2_label['Label'])\n",
    "\n",
    "\n",
    "    # class 1 and 0 are imbalanced, use weightedsampler to generate training data batch \n",
    "    class1_tr = train_index['Label'].sum()\n",
    "    num_classes = 2\n",
    "    class_sample_counts = [len(train_index) - class1_tr, class1_tr]\n",
    "    # compute weight for all the samples in the dataset\n",
    "    # samples_weights contain the probability for each example in dataset to be sampled  \n",
    "    class_weights = 1./torch.Tensor(class_sample_counts)\n",
    "    # get list of all labels \n",
    "    train_targets = train_index['Label'].values\n",
    "    # then get the weight for each target!\n",
    "    train_samples_weight = [class_weights[class_id] for class_id in train_targets]\n",
    "    #print(train_samples_weight)\n",
    "    train_sampler = WeightedRandomSampler(train_samples_weight, len(train_samples_weight), replacement=True)\n",
    "\n",
    "\n",
    "\n",
    "    config={'img_pix_nu':49152,\n",
    "            'emb_size': 256,\n",
    "            'head_nu':1,# 2\n",
    "            'drop_rate' :0.2,\n",
    "            'rnn_int_size': 256*3+9+3,\n",
    "            'rnn_hidden_size': 128, # was 256\n",
    "            'rnn_layers': 1}# was 2\n",
    "\n",
    "    model=CCBTP_attn(config)\n",
    "    \n",
    "    model=model.cuda()\n",
    "\n",
    "\n",
    "    train_1= CCBTP_data(train_index, HPMRI, NMR, NMR_mask,sag_path,cor_path,ax_path,hp_path )\n",
    "    train_loader_1 = DataLoader(train_1, batch_size=15)\n",
    "    #train_loader_1 = DataLoader(train_1, sampler=train_sampler, batch_size=15)\n",
    "\n",
    "    test_1= CCBTP_data(test_index, HPMRI, NMR, NMR_mask,sag_path,cor_path,ax_path,hp_path)\n",
    "    test_loader = DataLoader(test_1, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "    epoch_loss=[]\n",
    "    ind = 0\n",
    "    training_start_time = time.time()\n",
    "    auc_max = 0.0\n",
    "    if not val:\n",
    "        for j in range(30):\n",
    "            epoch_start_time = time.time()\n",
    "            print('train_loader_1:')\n",
    "            all_loss,model=train_unit(model,train_loader_1,torch.tensor([1.0,2.0]))\n",
    "            epoch_loss.append(np.mean(np.array(all_loss)))\n",
    "            print('-------training loss', np.mean(np.array(all_loss)))\n",
    "            \n",
    "            rall_result_1,rall_gold_1,mouse_n=val_unit(model,test_loader)\n",
    "            try:\n",
    "                auc2=roc_auc_score(np.array(rall_gold_1).flatten(),np.array(rall_result_1).flatten())\n",
    "                print('AUC_epoch {:8.5f}'.format(auc2))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if auc_max < auc2:\n",
    "                print('Found a bigger auc')\n",
    "                print('Saving model ...')\n",
    "                #torch.save(model.state_dict(), savemodelpath)\n",
    "                auc_max = auc2\n",
    "                save_path='./model_result/raw/task2/'+str(dayy)+'/'+'fold_'+str(i)+'.csv'\n",
    "                with open(save_path, 'wb') as f:\n",
    "                    np.savetxt(f, np.array(np.asarray(mouse_n).reshape(-1,3)), delimiter=',', fmt='%d') \n",
    "        print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n",
    "    else:\n",
    "        print('Starting validation only....')\n",
    "        model.load_state_dict(torch.load('./model_result/raw/task2/att_1_day_'+dayy+'_class.pth')) #dayy\n",
    "        model.eval()\n",
    "        print('Test data...')\n",
    "        rall_result_1,rall_gold_1=val_unit(model,test_loader,sv=True)\n",
    "        auc2=roc_auc_score(np.array(rall_gold_1).flatten(),np.array(rall_result_1).flatten())\n",
    "        print('AUC_epoch {:8.5f}'.format(auc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cabf638",
   "metadata": {},
   "outputs": [],
   "source": [
    "rall_result_1,rall_gold_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "'./model_result/raw/task2/'+str(dayy)+'/'+'fold_'+str(1)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c53028",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a41f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60118df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
