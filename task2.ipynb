{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01364009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from libauc.losses import AUCMLoss \n",
    "from libauc.optimizers import PESG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d910fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_optimizer import PCGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ebab875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17708/2080976236.py:6: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader,WeightedRandomSampler\n",
    "from torch.nn import MultiheadAttention,Linear, ReLU, RNN,Sigmoid,Softmax\n",
    "import torch \n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from sklearn.metrics import mean_absolute_error,r2_score,roc_auc_score,f1_score,balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split,RepeatedKFold\n",
    "#sklearn.model_selection.RepeatedKFold\n",
    "#from pcgrad import PCGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f8f3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import NMR_matrix, NMR_mask_matrix, return_NMR_pad, return_pad, check_max_len_img, FindCorner, FindNonzero2D\n",
    "from modules import return_img_pad, check_max_len, check_max_len_img_hp, return_ph_pad, LoadData, mult_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4662c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCBTP_data(Dataset):\n",
    "\n",
    "    def __init__(self, mouse_index, HPMRI, NMR, NMR_mask,sag_path,cor_path,ax_path,hp_path ):\n",
    "        \n",
    "        self.mouse_index = mouse_index\n",
    "        self.HPMRI=HPMRI\n",
    "        self.NMR=NMR\n",
    "        self.NMR_mask=NMR_mask\n",
    "        self.sag_path=sag_path\n",
    "\n",
    "        self.cor_path=cor_path\n",
    "        self.ax_path=ax_path\n",
    "        self.sag_max, self.sag_loc =check_max_len_img(sag_path)\n",
    "        self.cor_max, self.cor_loc=check_max_len_img(cor_path)\n",
    "        self.ax_max, self.ax_loc=check_max_len_img(ax_path)\n",
    "        self.max_seq=check_max_len(HPMRI)\n",
    "        \n",
    "        \n",
    "        self.hp_path=hp_path\n",
    "        self.hp_max_r, self.hp_max_c= check_max_len_img_hp(hp_path) #['agg_index']\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mouse_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get locations of a fixed 2d area working for ax, sag and cor \n",
    "        loc_all = []\n",
    "        for i in range(4):\n",
    "            if i%2==0:\n",
    "                loc_all.append(min(self.sag_loc[i],self.cor_loc[i],self.ax_loc[i]))\n",
    "            else:\n",
    "                loc_all.append(max(self.sag_loc[i],self.cor_loc[i],self.ax_loc[i]))\n",
    "        mouse=self.mouse_index.iloc[idx].Mouse_Name\n",
    "\n",
    "        coh=self.mouse_index.iloc[idx].Cohort\n",
    "\n",
    "        mouse_class = self.mouse_index.iloc[idx].Label\n",
    "\n",
    "        pt_HPMRI=self.HPMRI[self.HPMRI.Mouse_Name==mouse]\n",
    "\n",
    "        pt_HPMRI=pt_HPMRI.sort_values(by='Days_Elapsed').drop(columns=['Mouse_Name','Cohort','Days_Elapsed']).values\n",
    "        pt_HPMRI=return_pad(pt_HPMRI,self.max_seq)\n",
    "        pt_NMR=self.NMR[self.NMR.Mouse_Name==mouse]\n",
    "        #pt_NMR=pt_NMR.sort_values(by='Days_Elapsed').drop(columns=['Mouse_Name','Cohort','Days_Elapsed','tumor_index']).values\n",
    "        pt_NMR=pt_NMR.sort_values(by='Days_Elapsed').drop(columns=['Mouse_Name','Cohort','Days_Elapsed']).values\n",
    "        \n",
    "        pt_NMR=return_pad(pt_NMR,self.max_seq)\n",
    "\n",
    "        pt_NMR_mask=self.NMR_mask[self.NMR_mask.Mouse_Name==mouse]\n",
    "        pt_NMR_mask=pt_NMR_mask.sort_values(by='Days_Elapsed').drop(columns=['Mouse_Name','Cohort','Days_Elapsed']).values\n",
    "        pt_NMR_mask=return_pad(pt_NMR_mask,self.max_seq)\n",
    "    \n",
    "        pt_sag=self.sag_path[self.sag_path.Mouse_Name==mouse]\n",
    "        pt_sag=return_img_pad (pt_sag,self.max_seq,self.sag_max,loc_all)\n",
    "        pt_cor=self.cor_path[self.cor_path.Mouse_Name==mouse]\n",
    "        pt_cor=return_img_pad (pt_cor,self.max_seq,self.cor_max,loc_all)\n",
    "        pt_ax=self.ax_path[self.ax_path.Mouse_Name==mouse]\n",
    "        pt_ax=return_img_pad(pt_ax,self.max_seq,self.ax_max,loc_all)  \n",
    "\n",
    "\n",
    "\n",
    "        # ht_hp, raw data\n",
    "        #print('pt_hp', self.hp_path.shape)      \n",
    "        pt_hp=self.hp_path[self.hp_path.Mouse_Name==mouse]\n",
    "        pt_hp=return_ph_pad(pt_hp, self.max_seq, self.hp_max_r, self.hp_max_c)\n",
    " \n",
    "       \n",
    "        return (pt_HPMRI,pt_NMR,pt_NMR_mask,pt_sag,pt_cor,pt_ax, mouse_class, pt_hp, mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2790726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCBTP_attn(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CCBTP_attn, self).__init__()\n",
    "        self.emb_size=config['emb_size']\n",
    "        \n",
    "        self.Lin_img_1=nn.Linear(config['img_pix_nu'],config['emb_size'],bias=False)\n",
    "        self.Lin_img_2=nn.Linear(config['img_pix_nu'],config['emb_size'],bias=False)\n",
    "        self.Lin_img_3=nn.Linear(config['img_pix_nu'],config['emb_size'],bias=False)\n",
    "        \n",
    "        self.Lin_img_all=nn.Linear(config['emb_size']*9,config['emb_size']*3)\n",
    "        self.MuA_1=mult_attn(config).cuda()\n",
    "        self.MuA_2=mult_attn(config).cuda()\n",
    "        self.MuA_3=mult_attn(config).cuda()\n",
    "        self.relu=ReLU()\n",
    "        self.sigmoid=Sigmoid()\n",
    "        self.Softmax=Softmax()\n",
    "\n",
    "\n",
    "\n",
    "        self.conv1_3d = self._conv_layer_set_3d(1, 64)\n",
    "        self.conv2_3d = self._conv_layer_set_3d(64, 128, h_size = 1)\n",
    "        self.conv3_3d = self._conv_layer_set_3d(128, self.emb_size, h_size = 1)\n",
    "\n",
    "        self.conv_hp1 = self._conv_layer_set_2d(1, 8)\n",
    "        self.conv_hp2 = self._conv_layer_set_2d(8, 16)\n",
    "        \n",
    "        self.rnn_t=RNN(input_size=8,hidden_size=3,num_layers=config['rnn_layers'],\n",
    "                    batch_first=True,dropout=config['drop_rate']\n",
    "                    )\n",
    "        self.rnn_hp=RNN(input_size=9,hidden_size=9,num_layers=config['rnn_layers'],\n",
    "                    batch_first=True,dropout=config['drop_rate']\n",
    "                    )\n",
    "        \n",
    "        self.rnn_hp_raw=RNN(input_size=280,hidden_size=config['rnn_hidden_size'],num_layers=config['rnn_layers'],\n",
    "                    batch_first=True,dropout=config['drop_rate']\n",
    "                    )\n",
    "        \n",
    "        self.final_lin2=nn.Linear(908,2,bias=True) \n",
    "        \n",
    "        \n",
    "    def forward(self,pt_HPMRI,pt_sag,pt_cor,pt_ax,pt_hp, NMR_data): \n",
    "\n",
    "        pt_sag=pt_sag.permute(1, 0,2,3,4)        \n",
    "        pt_cor=pt_cor.permute(1, 0,2,3, 4)\n",
    "        pt_ax=pt_ax.permute(1, 0,2,3,4)\n",
    "        pt_hp=pt_hp.permute(1, 0,2,3)\n",
    "        convs_size_sag, convs_size_cor, convs_size_ax= pt_sag.size(2), pt_cor.size(2), pt_ax.size(2)\n",
    "        timestep=pt_ax.size()[0]\n",
    "        batch=pt_ax.size()[1]\n",
    "        input_rnn=torch.empty(size=(timestep*3, batch ,self.emb_size))\n",
    "        input_rnn_hp=torch.empty(size=(timestep, batch ,280))\n",
    "        for i in range(timestep):\n",
    "\n",
    "            # 3d for images\n",
    "            pt_sag_temp=pt_sag[i].float()\n",
    "            pt_sag_temp = self.convs_3d(pt_sag_temp)\n",
    "\n",
    "            pt_cor_temp=pt_cor[i].float()\n",
    "            pt_cor_temp = self.convs_3d(pt_cor_temp)\n",
    "            \n",
    "            pt_ax_temp=pt_ax[i].float()\n",
    "            pt_ax_temp = self.convs_3d(pt_ax_temp)\n",
    "\n",
    "\n",
    "            pt_hp_temp=pt_hp[i].float().unsqueeze(1)\n",
    "            pt_hp_temp = self.conv_hp1(pt_hp_temp)\n",
    "            pt_hp_temp = self.conv_hp2(pt_hp_temp)\n",
    "            #print(pt_hp_temp.size())\n",
    "            pt_hp_temp = torch.max(pt_hp_temp, 1)[0].reshape(batch, -1)\n",
    "\n",
    "            input_rnn[i], input_rnn[i+timestep], input_rnn[i+timestep*2]= pt_sag_temp, pt_cor_temp, pt_ax_temp\n",
    "            input_rnn_hp[i] = pt_hp_temp\n",
    "\n",
    "        pt_sag_temp = input_rnn[:timestep,:,:].cuda()\n",
    "        pt_cor_temp = input_rnn[timestep:timestep*2,:,:].cuda()\n",
    "        pt_ax_temp = input_rnn[timestep*2:,:,:].cuda()\n",
    "        \n",
    "        pt_ax_attn=self.MuA_1(pt_ax_temp,pt_cor_temp,pt_sag_temp)\n",
    "        pt_cor_attn=self.MuA_2(pt_cor_temp,pt_ax_temp,pt_sag_temp)\n",
    "        pt_sag_attn=self.MuA_3(pt_sag_temp,pt_cor_temp,pt_ax_temp)\n",
    "        pt_att_final=self.Lin_img_all(torch.cat((pt_ax_attn, pt_cor_attn,pt_sag_attn),dim=1))\n",
    "        \n",
    "        pt_att_final=self.relu(pt_att_final)\n",
    "\n",
    "        # To here, images along days from (batch, days, embd) to (batch, embd)\n",
    "        # HPMRI w/wo raw, tumor still (batch, days, emb)\n",
    "        \n",
    "        #all_time_attn=all_time_attn.permute(1, 0,2).cuda()\n",
    "\n",
    "        pt_HPMRI,_ = self.rnn_hp(pt_HPMRI)\n",
    "        rnn_output_hp,_ = self.rnn_hp_raw(input_rnn_hp.permute(1, 0,2).cuda())\n",
    "        pt_tumor, _ = self.rnn_t(NMR_data)\n",
    "\n",
    "\n",
    "        pt_HPMRI, rnn_output_hp, pt_tumor = pt_HPMRI[:,-1,:], rnn_output_hp[:,-1,:], pt_tumor[:,-1,:]\n",
    "        \n",
    "        all_rnn_input=torch.cat((pt_att_final,rnn_output_hp,pt_HPMRI,pt_tumor),dim=1)\n",
    "        \n",
    "        \n",
    "        pred=self.final_lin2(all_rnn_input)\n",
    "        #pred =self.Softmax(pred)\n",
    "        #pred = self.sigmoid(pred)\n",
    "        \n",
    "        return pred \n",
    "\n",
    "    def _conv_layer_set_2d(self, in_c, out_c):\n",
    "        conv_layer = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=( 3, 3), padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((3, 3)),\n",
    "        )\n",
    "        return conv_layer\n",
    "\n",
    "    def _conv_layer_set_3d(self, in_c, out_c, h_size=2):\n",
    "        conv_layer = nn.Sequential(\n",
    "        nn.Conv3d(in_c, out_c, kernel_size=( h_size, 3, 3), padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool3d((h_size, 3, 3)),\n",
    "        )\n",
    "        return conv_layer\n",
    "\n",
    "    def convs_3d(self,pt_sag_temp):\n",
    "        \n",
    "        pt_sag_temp = pt_sag_temp.unsqueeze(1)\n",
    "        pt_sag_temp=self.conv1_3d(pt_sag_temp)\n",
    "        pt_sag_temp=self.conv2_3d(pt_sag_temp)\n",
    "        pt_sag_temp=self.conv3_3d(pt_sag_temp)\n",
    "        pt_sag_temp=pt_sag_temp.reshape(pt_sag_temp.size(0), self.emb_size, -1).max(-1)[0]\n",
    "        \n",
    "        return pt_sag_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdcb5ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unit(model,dataloader,class_weights):\n",
    "    optimizer=Adam(model.parameters(),lr=0.001)\n",
    "    all_loss=[]\n",
    "    model.train()\n",
    "    #lr = 0.1\n",
    "    #margin = 1.0\n",
    "    #epoch_decay = 0.003 # refers gamma in the paper\n",
    "    #weight_decay = 0.0001\n",
    "    #loss_fn = AUCMLoss()\n",
    "    #optimizer = PESG(model.parameters(),\n",
    "                 #loss_fn=loss_fn,\n",
    "                 #lr=0.05,\n",
    "                 #momentum=0.9,\n",
    "                 #margin=margin,\n",
    "                 #epoch_decay=epoch_decay,\n",
    "                 #weight_decay=weight_decay) \n",
    "    #criterion=nn.BCELoss()\n",
    "    criterion= nn.CrossEntropyLoss(weight=class_weights.cuda())\n",
    "    mouse_n, inf = [], []\n",
    "    for iteration, data_u in enumerate(dataloader):\n",
    "        HPNRI_data=data_u[0].float() \n",
    "        NMR_data=data_u[1].float() \n",
    "        NMR_data_mask_1=data_u[2].float() \n",
    "        sag_data=data_u[3].float()\n",
    "        cor_data=data_u[4].float()\n",
    "        ax_data=data_u[5].float()\n",
    "        classinf=Variable(data_u[6]).float()\n",
    "        pt_hp = Variable(data_u[7]).float()\n",
    "\n",
    "        \n",
    "        HPNRI_data=HPNRI_data.cuda()\n",
    "        NMR_data=NMR_data.cuda()\n",
    "        sag_data=sag_data.cuda()\n",
    "        cor_data=cor_data.cuda()\n",
    "        ax_data=ax_data.cuda()\n",
    "        classinf= classinf.cuda()\n",
    "        pt_hp = pt_hp.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        rnn_output=model(HPNRI_data,sag_data,cor_data,ax_data, pt_hp, NMR_data)\n",
    "        #rnn_output = torch.softmax(rnn_output)\n",
    "        #print(rnn_output)\n",
    "        loss = criterion(rnn_output, classinf.long())\n",
    "        #loss=criterion(rnn_output.reshape(-1),classinf)\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_loss.append(loss.cpu().data.numpy().item())\n",
    "    \n",
    "    return all_loss,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd817b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_unit(model,dataloader, sv=False):\n",
    "    all_result_1=[]\n",
    "    all_gold_1=[]\n",
    "\n",
    "    all_loss=[]\n",
    "    model.eval() \n",
    "\n",
    "    with torch.no_grad():\n",
    "        mouse_n, inf = [], []\n",
    "        for iteration, data_u in enumerate(dataloader):\n",
    "            HPNRI_data=data_u[0].float() \n",
    "            NMR_data=data_u[1].float() \n",
    "            NMR_data_mask_1=data_u[2].float() \n",
    "            sag_data=data_u[3].float()\n",
    "            cor_data=data_u[4].float()\n",
    "            ax_data=data_u[5].float()\n",
    "\n",
    "            classinf=Variable(data_u[6]).float()\n",
    "            pt_hp = Variable(data_u[7]).float()\n",
    "\n",
    "            # mouse_n: name, label, prediction(0/1),prediction_prob\n",
    "            \n",
    "            mouse_n = np.concatenate((mouse_n,data_u[8].numpy()))\n",
    "            mouse_n = np.concatenate((mouse_n,data_u[6].numpy().reshape(-1)))\n",
    "            \n",
    "            \n",
    "            HPNRI_data=HPNRI_data.cuda()\n",
    "            NMR_data=NMR_data.cuda()\n",
    "            sag_data=sag_data.cuda()\n",
    "            cor_data=cor_data.cuda()\n",
    "            ax_data=ax_data.cuda()\n",
    "            classinf= classinf.cuda()\n",
    "            pt_hp = pt_hp.cuda()\n",
    "\n",
    "            rnn_output=model(HPNRI_data,sag_data,cor_data,ax_data, pt_hp, NMR_data)\n",
    "            #rnn_output = torch.sigmoid(rnn_output)\n",
    "            #print(rnn_output)\n",
    "            #print( )\n",
    "            pred_ = rnn_output.cpu().detach().numpy().argmax(axis=1)\n",
    "            #print(pred_)\n",
    "            #pred_[pred_ < 0.5] = 0\n",
    "            #pred_[pred_ >= 0.5] = 1\n",
    "            mouse_n = np.concatenate((mouse_n,pred_.reshape(-1)))\n",
    " \n",
    "            all_result_1.append(pred_)#rnn_output.cpu().detach().numpy())\n",
    "            all_gold_1.append(classinf.cpu().detach().numpy())\n",
    "            \n",
    "\n",
    "        if sv:\n",
    "            with open('task2_predictions.csv', 'wb') as f:\n",
    "                np.savetxt(f, np.array(np.asarray(mouse_n).reshape(-1,3)), delimiter=',', fmt='%d') \n",
    "            \n",
    "    return all_result_1,all_gold_1,mouse_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82398ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "config={'img_pix_nu':49152,\n",
    "            'emb_size': 256,\n",
    "            'head_nu':1,# 2\n",
    "            'drop_rate' :0.2,\n",
    "            'rnn_int_size': 256*3+9+3,\n",
    "            'rnn_hidden_size': 128, # was 256\n",
    "            'rnn_layers': 1}# was 2\n",
    "\n",
    "model=CCBTP_attn(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61501101",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = False # if validation only\n",
    "    \n",
    "device=1\n",
    "torch.cuda.set_device(device)\n",
    "dayy = '41'\n",
    "print('Day on', dayy)\n",
    "\n",
    "rr = 'raw/task2/'\n",
    "\n",
    "        \n",
    "data_path='./NMR_Prediction/NMR_Before_Day_'+dayy+'/'\n",
    "\n",
    "\n",
    "savemodelpath='./model_result/'+rr+'att_1_day_'+dayy+'_class.pth'\n",
    "if not os.path.exists('./model_result/raw/task2/'+dayy):\n",
    "    os.makedirs('./model_result/raw/task2/'+dayy)\n",
    "\n",
    "filelist=os.listdir(data_path)\n",
    "filelist=[i for i in filelist if i.startswith('all')]\n",
    "filelist.sort()\n",
    "\n",
    "\n",
    "    # Load data from Treated cohort\n",
    "HPMRI, HPMRI_mask, NMR, NMR_true, NMR_mask, tumor, tumor_mask, sag_path, cor_path, ax_path, hp_path= LoadData(data_path, cohort = 'Treated')\n",
    "\n",
    "    # Load label\n",
    "task2_label = pd.read_csv('./treated_mice_day41_effect.csv')\n",
    "task2_label.columns=['Mouse_Name','Cohort','Label']\n",
    "task2_label['Label']=np.where(task2_label['Label']=='Yes',1,0)\n",
    "\n",
    "\n",
    "rkf=RepeatedKFold(n_repeats=5, n_splits=3, random_state=2652124)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(rkf.split(task2_label)):\n",
    "    train_index=task2_label.iloc[train_index]\n",
    "    test_index=task2_label.iloc[test_index]\n",
    "    \n",
    "\n",
    "    #train_index,test_index=train_test_split(task2_label,train_size=0.8,stratify=task2_label['Label'])\n",
    "\n",
    "\n",
    "    # class 1 and 0 are imbalanced, use weightedsampler to generate training data batch \n",
    "    class1_tr = train_index['Label'].sum()\n",
    "    num_classes = 2\n",
    "    class_sample_counts = [len(train_index) - class1_tr, class1_tr]\n",
    "    # compute weight for all the samples in the dataset\n",
    "    # samples_weights contain the probability for each example in dataset to be sampled  \n",
    "    class_weights = 1./torch.Tensor(class_sample_counts)\n",
    "    # get list of all labels \n",
    "    train_targets = train_index['Label'].values\n",
    "    # then get the weight for each target!\n",
    "    train_samples_weight = [class_weights[class_id] for class_id in train_targets]\n",
    "    #print(train_samples_weight)\n",
    "    train_sampler = WeightedRandomSampler(train_samples_weight, len(train_samples_weight), replacement=True)\n",
    "\n",
    "\n",
    "\n",
    "    config={'img_pix_nu':49152,\n",
    "            'emb_size': 256,\n",
    "            'head_nu':1,# 2\n",
    "            'drop_rate' :0.2,\n",
    "            'rnn_int_size': 256*3+9+3,\n",
    "            'rnn_hidden_size': 128, # was 256\n",
    "            'rnn_layers': 1}# was 2\n",
    "\n",
    "    model=CCBTP_attn(config)\n",
    "    \n",
    "    model=model.cuda()\n",
    "\n",
    "\n",
    "    train_1= CCBTP_data(train_index, HPMRI, NMR, NMR_mask,sag_path,cor_path,ax_path,hp_path )\n",
    "    train_loader_1 = DataLoader(train_1, batch_size=15)\n",
    "    #train_loader_1 = DataLoader(train_1, sampler=train_sampler, batch_size=15)\n",
    "\n",
    "    test_1= CCBTP_data(test_index, HPMRI, NMR, NMR_mask,sag_path,cor_path,ax_path,hp_path)\n",
    "    test_loader = DataLoader(test_1, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "    epoch_loss=[]\n",
    "    ind = 0\n",
    "    training_start_time = time.time()\n",
    "    auc_max = 0.0\n",
    "    if not val:\n",
    "        for j in range(30):\n",
    "            epoch_start_time = time.time()\n",
    "            print('train_loader_1:')\n",
    "            all_loss,model=train_unit(model,train_loader_1,torch.tensor([1.0,2.0]))\n",
    "            epoch_loss.append(np.mean(np.array(all_loss)))\n",
    "            print('-------training loss', np.mean(np.array(all_loss)))\n",
    "            \n",
    "            rall_result_1,rall_gold_1,mouse_n=val_unit(model,test_loader)\n",
    "            try:\n",
    "                auc2=roc_auc_score(np.array(rall_gold_1).flatten(),np.array(rall_result_1).flatten())\n",
    "                print('AUC_epoch {:8.5f}'.format(auc2))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if auc_max < auc2:\n",
    "                print('Found a bigger auc')\n",
    "                print('Saving model ...')\n",
    "                #torch.save(model.state_dict(), savemodelpath)\n",
    "                auc_max = auc2\n",
    "                save_path='./model_result/raw/task2/'+str(dayy)+'/'+'fold_'+str(i)+'.csv'\n",
    "                with open(save_path, 'wb') as f:\n",
    "                    np.savetxt(f, np.array(np.asarray(mouse_n).reshape(-1,3)), delimiter=',', fmt='%d') \n",
    "        print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n",
    "    else:\n",
    "        print('Starting validation only....')\n",
    "        model.load_state_dict(torch.load('./model_result/raw/task2/att_1_day_'+dayy+'_class.pth')) #dayy\n",
    "        model.eval()\n",
    "        print('Test data...')\n",
    "        rall_result_1,rall_gold_1=val_unit(model,test_loader,sv=True)\n",
    "        auc2=roc_auc_score(np.array(rall_gold_1).flatten(),np.array(rall_result_1).flatten())\n",
    "        print('AUC_epoch {:8.5f}'.format(auc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60118df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
